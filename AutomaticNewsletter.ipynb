{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3afa01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from docx import Document\n",
    "from docx.shared import Pt, RGBColor\n",
    "from docx.oxml.shared import OxmlElement, qn\n",
    "from docx.oxml import ns\n",
    "\n",
    "from docx.oxml import OxmlElement, ns\n",
    "from docx.oxml.ns import qn\n",
    "from docx.opc.constants import RELATIONSHIP_TYPE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b04112",
   "metadata": {},
   "source": [
    "### semantic embeddings models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b793994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"princeton-nlp/sup-simcse-roberta-large\")\n",
    " \n",
    "model = AutoModel.from_pretrained(\"princeton-nlp/sup-simcse-roberta-large\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdbb885",
   "metadata": {},
   "source": [
    "### openai models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bedb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key= \"YOUR-OPENAI-KEY\"\n",
    "\n",
    "def get_completion(prompt, model): \n",
    "    messages = [ {\"role\": \"system\", \"content\": \"You are a helpful assistant that respects very precisely the instructions given.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f52f34",
   "metadata": {},
   "source": [
    "### variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc89c03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Articles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b657070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Vector\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17302fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titre</th>\n",
       "      <th>Resume</th>\n",
       "      <th>Date</th>\n",
       "      <th>Url</th>\n",
       "      <th>Website</th>\n",
       "      <th>politique</th>\n",
       "      <th>géopolitique</th>\n",
       "      <th>sociologique</th>\n",
       "      <th>démographie</th>\n",
       "      <th>économie micro</th>\n",
       "      <th>...</th>\n",
       "      <th>International</th>\n",
       "      <th>Monde</th>\n",
       "      <th>Industrie</th>\n",
       "      <th>Marque et enseigne</th>\n",
       "      <th>Services</th>\n",
       "      <th>Energie</th>\n",
       "      <th>Construction</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Mobilité</th>\n",
       "      <th>Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Un journal non aligné</td>\n",
       "      <td>Le Monde diplomatique, un journal non aligné, ...</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>https://www.monde-diplomatique.fr/2023/11/BREV...</td>\n",
       "      <td>Monde Diplomatique</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>...</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Un renoncement français</td>\n",
       "      <td>L'article intitulé \"Il n'y aura pas de rue Emm...</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>https://www.monde-diplomatique.fr/2023/11/BREV...</td>\n",
       "      <td>Monde Diplomatique</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>...</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quand la guerre percute la politique française</td>\n",
       "      <td>Le nouveau conflit au Proche-Orient a eu un im...</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>https://www.monde-diplomatique.fr/2023/11/HALI...</td>\n",
       "      <td>Monde Diplomatique</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>...</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Loin du front, la société ukrainienne coupée e...</td>\n",
       "      <td>Dans un reportage intitulé \"Loin du front, la ...</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>https://www.monde-diplomatique.fr/2023/11/RICH...</td>\n",
       "      <td>Monde Diplomatique</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>...</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Non</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Israël-Palestine, l’engrenage guerrier</td>\n",
       "      <td>L'article \"Israël-Palestine, l'engrenage guerr...</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>https://www.monde-diplomatique.fr/2023/11/BELK...</td>\n",
       "      <td>Monde Diplomatique</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>...</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Blue bonds : de nouvelles lignes directrices p...</td>\n",
       "      <td>L'association internationale des marchés finan...</td>\n",
       "      <td>2023-11-07</td>\n",
       "      <td>https://lessentiel.novethic.fr/blog/business-c...</td>\n",
       "      <td>L'essentiel Novethic</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>...</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Titane, lithium : l'Union européenne ouvre un ...</td>\n",
       "      <td>La future législation européenne sur les matiè...</td>\n",
       "      <td>2023-11-07</td>\n",
       "      <td>https://reporterre.net/Titane-lithium-l-Union-...</td>\n",
       "      <td>Reporterre</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>...</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>La plus haute ZAD d'Europe remet en cause l'am...</td>\n",
       "      <td>Des militants écologistes ont occupé le glacie...</td>\n",
       "      <td>2023-11-07</td>\n",
       "      <td>https://www.latribune.fr/opinions/tribunes/la-...</td>\n",
       "      <td>La Tribune</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>...</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>La crise au Proche-Orient, une aubaine pour la...</td>\n",
       "      <td>La crise au Proche-Orient profite à la Russie ...</td>\n",
       "      <td>2023-11-07</td>\n",
       "      <td>https://www.latribune.fr/opinions/tribunes/la-...</td>\n",
       "      <td>La Tribune</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>...</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>Les start-up françaises ont levé 759 millions ...</td>\n",
       "      <td>Les start-up françaises ont réalisé une levée ...</td>\n",
       "      <td>2023-11-05</td>\n",
       "      <td>https://www.journaldunet.com/start-up/1526775-...</td>\n",
       "      <td>Journaldunet</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>...</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Oui</td>\n",
       "      <td>Non</td>\n",
       "      <td>Non</td>\n",
       "      <td>Oui</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>590 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Titre  \\\n",
       "0                                Un journal non aligné   \n",
       "1                              Un renoncement français   \n",
       "2       Quand la guerre percute la politique française   \n",
       "3    Loin du front, la société ukrainienne coupée e...   \n",
       "4               Israël-Palestine, l’engrenage guerrier   \n",
       "..                                                 ...   \n",
       "585  Blue bonds : de nouvelles lignes directrices p...   \n",
       "586  Titane, lithium : l'Union européenne ouvre un ...   \n",
       "587  La plus haute ZAD d'Europe remet en cause l'am...   \n",
       "588  La crise au Proche-Orient, une aubaine pour la...   \n",
       "589  Les start-up françaises ont levé 759 millions ...   \n",
       "\n",
       "                                                Resume        Date  \\\n",
       "0    Le Monde diplomatique, un journal non aligné, ...  2023-11-01   \n",
       "1    L'article intitulé \"Il n'y aura pas de rue Emm...  2023-11-01   \n",
       "2    Le nouveau conflit au Proche-Orient a eu un im...  2023-11-01   \n",
       "3    Dans un reportage intitulé \"Loin du front, la ...  2023-11-01   \n",
       "4    L'article \"Israël-Palestine, l'engrenage guerr...  2023-11-01   \n",
       "..                                                 ...         ...   \n",
       "585  L'association internationale des marchés finan...  2023-11-07   \n",
       "586  La future législation européenne sur les matiè...  2023-11-07   \n",
       "587  Des militants écologistes ont occupé le glacie...  2023-11-07   \n",
       "588  La crise au Proche-Orient profite à la Russie ...  2023-11-07   \n",
       "589  Les start-up françaises ont réalisé une levée ...  2023-11-05   \n",
       "\n",
       "                                                   Url               Website  \\\n",
       "0    https://www.monde-diplomatique.fr/2023/11/BREV...    Monde Diplomatique   \n",
       "1    https://www.monde-diplomatique.fr/2023/11/BREV...    Monde Diplomatique   \n",
       "2    https://www.monde-diplomatique.fr/2023/11/HALI...    Monde Diplomatique   \n",
       "3    https://www.monde-diplomatique.fr/2023/11/RICH...    Monde Diplomatique   \n",
       "4    https://www.monde-diplomatique.fr/2023/11/BELK...    Monde Diplomatique   \n",
       "..                                                 ...                   ...   \n",
       "585  https://lessentiel.novethic.fr/blog/business-c...  L'essentiel Novethic   \n",
       "586  https://reporterre.net/Titane-lithium-l-Union-...            Reporterre   \n",
       "587  https://www.latribune.fr/opinions/tribunes/la-...            La Tribune   \n",
       "588  https://www.latribune.fr/opinions/tribunes/la-...            La Tribune   \n",
       "589  https://www.journaldunet.com/start-up/1526775-...          Journaldunet   \n",
       "\n",
       "    politique géopolitique sociologique démographie économie micro  ...  \\\n",
       "0         Non          Non          Non         Non            Non  ...   \n",
       "1         Non          Non          Non         Non            Non  ...   \n",
       "2         Non          Non          Non         Non            Non  ...   \n",
       "3         Non          Non          Non         Non            Non  ...   \n",
       "4         Non          Non          Non         Non            Non  ...   \n",
       "..        ...          ...          ...         ...            ...  ...   \n",
       "585       Non          Non          Non         Non            Non  ...   \n",
       "586       Oui          Non          Non         Non            Non  ...   \n",
       "587       Non          Non          Non         Non            Non  ...   \n",
       "588       Oui          Oui          Non         Non            Non  ...   \n",
       "589       Non          Non          Non         Non            Non  ...   \n",
       "\n",
       "    International Monde Industrie Marque et enseigne Services Energie  \\\n",
       "0             Oui   Oui       Non                Non      Non     Oui   \n",
       "1             Oui   Oui       Non                Non      Non     Oui   \n",
       "2             Oui   Oui       Non                Non      Non     Oui   \n",
       "3             Oui   Oui       Non                Non      Non     Oui   \n",
       "4             Oui   Oui       Non                Non      Non     Oui   \n",
       "..            ...   ...       ...                ...      ...     ...   \n",
       "585           Oui   Oui       Non                Non      Non     Non   \n",
       "586           Oui   Oui       Oui                Non      Non     Non   \n",
       "587           Non   Non       Non                Non      Non     Non   \n",
       "588           Oui   Oui       Non                Non      Non     Non   \n",
       "589           Non   Non       Non                Non      Non     Oui   \n",
       "\n",
       "    Construction Utilities Mobilité Vector  \n",
       "0            Oui       Non      Non      0  \n",
       "1            Oui       Non      Non      0  \n",
       "2            Oui       Non      Non      0  \n",
       "3            Oui       Oui      Non      0  \n",
       "4            Oui       Non      Non      0  \n",
       "..           ...       ...      ...    ...  \n",
       "585          Non       Non      Non      0  \n",
       "586          Non       Non      Non      0  \n",
       "587          Non       Non      Non      0  \n",
       "588          Non       Non      Non      0  \n",
       "589          Non       Non      Oui      0  \n",
       "\n",
       "[590 rows x 29 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac0c166",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24087814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(sentence, tokenizer, model):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "   \n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51824a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_resume(resume,model,tokenizer):\n",
    "    \n",
    "    vector = vectorize(resume, tokenizer, model)\n",
    "        \n",
    "\n",
    "    if not isinstance(vector, str):\n",
    "        vector = ' '.join(map(str, vector))  \n",
    "    \n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08665cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    \n",
    "    if str(row['Vector']).strip()[0].isdigit():\n",
    "        \n",
    "        df.at[index, 'Vector'] = vectorize_resume(row['Resume'], model, tokenizer)\n",
    "        \n",
    "        # Sauvegarder le DataFrame après chaque mise à jour de ligne (si nécessaire)\n",
    "        df.to_csv(\"Articles_Vectorized.csv\", index=False, encoding='utf-8-sig')\n",
    "        \n",
    "### On pourrait utiliser la méthode apply mais comme le run est long sur CPU (SIM-CSE est un modèle à plus 1 Go),\n",
    "### On s'assure qu'on sauvegarde à chaque calcul\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361e38a4",
   "metadata": {},
   "source": [
    "### A ce stade, on a projeté les résumés dans un grand espace vectoriel capable de capturer sémantiquement les articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9c7e7f",
   "metadata": {},
   "source": [
    "### Le but est de regrouper les articles par thème, en définissant un seuil dans les clusters qui permet de dire si oui ou non deux articles sont du même thème, ce seuil est subjectif, plus il est petit plus les articles vont dans le même sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f0e362",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vec = pd.read_csv(\"Articles_Vectorized.csv\", index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a03793",
   "metadata": {},
   "source": [
    "### Algo (threshold à 11.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4dff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_clusters(df, data, threshold):\n",
    "    remaining_data = data.copy() ### Les vecteurs provenant de la projection des résumés par l'encodeur sémantique\n",
    "    remaining_df = df.copy() ### dataframe à néttoyer\n",
    "    optimal_clusters = []\n",
    "    cluster_number = 0\n",
    "\n",
    "    while remaining_data.shape[0] > 0:\n",
    "        k = 1 ###Nombre de clusters initialisé à 1 à chaque fois qu'on en trouve un nouveau, ce qui augmente la complexité\n",
    "        found = False\n",
    "\n",
    "        while not found:\n",
    "            kmeans = KMeans(n_clusters=k, random_state=0).fit(remaining_data) ###Algo KMeans\n",
    "            cluster_centers = kmeans.cluster_centers_\n",
    "            labels = kmeans.labels_\n",
    "\n",
    "            \n",
    "            for i in range(k): ###parcours des clusters\n",
    "                \n",
    "                cluster_mask = labels == i\n",
    "                cluster_data = remaining_data[cluster_mask]\n",
    "                centroid = np.mean(cluster_data, axis=0)\n",
    "\n",
    "                \n",
    "                distances = np.linalg.norm(cluster_data - centroid, axis=1)\n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "                if np.all(distances < threshold): ### Si un cluster est assez petit, on le garde\n",
    "                    max_distance = np.max(distances)\n",
    "                    print(max_distance)\n",
    "                    print(\"trouvé\")\n",
    "                    found = True\n",
    "                    cluster_number += 1  \n",
    "                    \n",
    "                    intra_cluster_distances = np.linalg.norm(cluster_data - cluster_data[:, np.newaxis], axis=2)\n",
    "                    representative_index = np.argmin(np.mean(intra_cluster_distances, axis=1))\n",
    "\n",
    "                    cluster_df = remaining_df.iloc[cluster_mask]\n",
    "                    representative_title = cluster_df.iloc[representative_index]['Title']\n",
    "                    cluster_info = { ##de la mise en forme pour le dataframe final\n",
    "                        \"Numéro du thème\": cluster_number, \n",
    "                        \"Url\": cluster_df['Url'].tolist(),\n",
    "                        \"Date\": cluster_df['Date'].tolist(),\n",
    "                        \"Resume\": cluster_df['Resume'].tolist(),\n",
    "                        \"Titre\": cluster_df['Title'].tolist(),\n",
    "                        \"Représentant\": representative_title,\n",
    "                        \n",
    "                    }\n",
    "                    optimal_clusters.append(cluster_info)\n",
    "                    print(cluster_info)\n",
    "\n",
    "                    \n",
    "                    remaining_data = remaining_data[~cluster_mask] ###On enlève les vecteurs qui appartiennent au cluster\n",
    "                    remaining_df = remaining_df.iloc[~cluster_mask]\n",
    "                    print(remaining_df.shape)\n",
    "                    break\n",
    "\n",
    "            if not found: ### Si aucun cluster assez petit trouvé On augmente le nombre de clusters possibles dans le K-Means\n",
    "                k += 1\n",
    "\n",
    "    return optimal_clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1973a185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_articles(df,threshold):\n",
    "    \n",
    "    df['Vector'] = df['Vector'].apply(lambda x: np.fromstring(x, dtype=float, sep=' '))\n",
    "    \n",
    "    data = np.array(df['Vector'].tolist())\n",
    "    print(data)\n",
    "    clusters_info = find_optimal_clusters(df, data, threshold=threshold)\n",
    "    \n",
    "    clusters_df = pd.DataFrame(clusters_info)\n",
    "    expanded_clusters_df = clusters_df.apply(pd.Series.explode \n",
    "                                             if not clusters_df.empty else clusters_df)\n",
    "\n",
    "    expanded_clusters_df[\"Représentant\"] = expanded_clusters_df[\"Représentant\"].astype(str)\n",
    "    expanded_clusters_df[\"Titre\"] = expanded_clusters_df[\"Titre\"].astype(str)\n",
    "    \n",
    "    \n",
    "    result = []\n",
    "\n",
    "\n",
    "    for _, row in expanded_clusters_df.iterrows():\n",
    "   \n",
    "        if row[\"Titre\"] == row[\"Représentant\"]:\n",
    "            result.append(\"oui\")\n",
    "        else:\n",
    "            result.append(\"non\")\n",
    "\n",
    "            \n",
    "    expanded_clusters_df[\"Est-il le représentant du thème ?\"] = result\n",
    "    \n",
    "\n",
    "    expanded_clusters_df['Nombre d\\'articles thème'] = expanded_clusters_df.groupby('Numéro du thème')['Resume'].transform('count')\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    merged_df = expanded_clusters_df.merge(df, on=\"Resume\", how=\"left\", suffixes=('', '_dup'))\n",
    "\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col != \"Resume\" and (col + '_dup') in merged_df.columns:\n",
    "            merged_df.drop(col + '_dup', axis=1, inplace=True)\n",
    "    \n",
    "    merged_df = merged_df.drop(columns=['Vector','Title'])\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a82efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = segmentation_articles(df_vec,11.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1201dfe",
   "metadata": {},
   "source": [
    "### Ecriture de la Newsletter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067ce656",
   "metadata": {},
   "source": [
    "### Filtre sur les plus gros clusters (thème d'actualité)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e274a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_dict = defaultdict(dict)\n",
    "\n",
    "for _, row in df_final.iterrows():\n",
    "    if row[\"Nombre d'articles thème\"] >= 6:\n",
    "           \n",
    "        theme = row['Numéro du thème']\n",
    "        url = row['Url']\n",
    "        resume = row['Resume']\n",
    "    \n",
    "\n",
    "    theme_dict[theme][url] = resume\n",
    "\n",
    "\n",
    "theme_dict = dict(theme_dict)\n",
    "\n",
    "\n",
    "reordered_theme_dict = {}\n",
    "\n",
    "for new_id, old_id in enumerate(sorted(theme_dict.keys()), start=1):\n",
    "    reordered_theme_dict[new_id] = theme_dict[old_id]\n",
    "\n",
    "\n",
    "theme_dict = reordered_theme_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8f6709",
   "metadata": {},
   "outputs": [],
   "source": [
    "representant_dict = defaultdict(dict)\n",
    "\n",
    "for _, row in df_finalv2.iterrows():\n",
    "    if row[\"Nombre d'articles thème\"] >= 6:\n",
    "           \n",
    "        if row['Est-il le représentant du thème ?'] == \"oui\":\n",
    "            theme = row['Numéro du thème']\n",
    "            titre = row['Titre']\n",
    "            representant_dict[theme] = titre\n",
    "\n",
    "\n",
    "representant_dict = dict(representant_dict)\n",
    "\n",
    "\n",
    "reordered_representant_dict= {}\n",
    "\n",
    "for new_id, old_id in enumerate(sorted(representant_dict.keys()), start=1):\n",
    "    reordered_representant_dict[new_id] = representant_dict[old_id]\n",
    "\n",
    "    \n",
    "representant_dict = reordered_representant_dict "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b760ebc",
   "metadata": {},
   "source": [
    "### Synthèse des clusters par gpt-4 et mise en forme Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f4262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def docx_add_hyperlink(paragraph, text, url, doc, is_external=True):\n",
    "    \n",
    "    run = paragraph.add_run(text)\n",
    "    run.font.size = Pt(12)  \n",
    "    run.font.color.rgb = RGBColor(0, 0, 255)\n",
    "    run.font.underline = True\n",
    "\n",
    "    hyperlink = OxmlElement('w:hyperlink')\n",
    "    id = doc.part.relate_to(url, RELATIONSHIP_TYPE.HYPERLINK, is_external=is_external)\n",
    "    hyperlink.set(qn('r:id'), id)\n",
    "\n",
    "  \n",
    "    run._r.getparent().replace(run._r, hyperlink)\n",
    "    hyperlink.append(run._r)\n",
    "    \n",
    "    return run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4960cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_preceding_word(text, start_index, end_index):\n",
    "    \n",
    "    word_pattern = re.compile(r'(\\b\\w+\\b\"?\\s?[?;!.>»]?|!\"|\\?\")(?=\\s*\\(?https)')\n",
    "\n",
    "    \n",
    "    match = word_pattern.search(text[start_index:end_index])\n",
    "    \n",
    "    if match:\n",
    "    \n",
    "        return match.group(1), match.start(1)\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592524ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_doc_with_hyperlinks(theme_dict, representing_dict, fichier):\n",
    "    url_pattern = r\"(?<=\\()?(https?://[^\\s)]+)(?=\\))?\"\n",
    "\n",
    "\n",
    "    doc = Document()\n",
    "    \n",
    "    for k in range(1, len(theme_dict) + 1):\n",
    "        doc.add_heading(representing_dict[k], level=1)\n",
    "        done = False \n",
    "        while not(done):\n",
    "            try :\n",
    "                prompt_final = f\"\"\" En adoptant un ton humoristique et légèrement décalé qui soit adapté, narre en 200 mots maximum une synthèse de revue de presse à la troisième personne.\n",
    "                Focus sur deux ou trois articles essentiels, en citant leurs URLs en entièreté, tirés de << {theme_dict[k]} >> \"\"\"\n",
    "                bullet_texte = get_completion(prompt_final, model = \"gpt-4\")\n",
    "                done = True\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        \n",
    "            \n",
    "                                      \n",
    "                                      \n",
    "       \n",
    "        \n",
    "       \n",
    "        urls = re.findall(url_pattern, bullet_texte)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        start_index = 0\n",
    "        p = doc.add_paragraph()\n",
    "\n",
    "        \n",
    "        print(bullet_texte)\n",
    "        print(urls)\n",
    "\n",
    "\n",
    "\n",
    "        for url in urls:\n",
    "            print(start_index)\n",
    "    \n",
    "            end_index = bullet_texte.rfind(url, start_index)\n",
    "            print(end_index)\n",
    "        \n",
    "        \n",
    "            if bullet_texte[end_index-1] == \"(\":\n",
    "                end_index += 1 \n",
    "            end_index += len(url)\n",
    "        \n",
    "        \n",
    " \n",
    "    \n",
    "            preceding_word, word_start = find_preceding_word(bullet_texte, start_index, end_index)\n",
    "            \n",
    "            \n",
    "    \n",
    "            end_word = bullet_texte[:end_index-len(url)].rfind(preceding_word, start_index)\n",
    "            print(end_word)\n",
    "        \n",
    "    \n",
    "            p.add_run(bullet_texte[start_index:end_word])\n",
    "    \n",
    "            print(bullet_texte[start_index:end_word])\n",
    "            \n",
    "            docx_add_hyperlink(p, preceding_word, url, doc)\n",
    "    \n",
    "    \n",
    "            start_index = end_index\n",
    "            if end_index < len(bullet_texte) and bullet_texte[end_index] == ')':\n",
    "                end_index += 1\n",
    "\n",
    "        if end_index < len(bullet_texte):\n",
    "            p.add_run(bullet_texte[end_index:])\n",
    "            \n",
    "        doc.save(fichier)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfd12fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fichier = f\"Revue de presse.docx\"\n",
    "create_doc_with_hyperlinks(theme_dict, representant_dict, fichier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
